"""
æ€§èƒ½å¯¹æ¯”æµ‹è¯•ï¼šEURAnovaPairAcqf vs EURAnovaPairAcqf_BatchOptimized

æµ‹è¯•ç›®æ ‡ï¼š
1. éªŒè¯æ•°å€¼ä¸€è‡´æ€§ï¼ˆä¼˜åŒ–å‰åç»“æœåº”å®Œå…¨ç›¸åŒï¼‰
2. æµ‹é‡æ€§èƒ½æå‡ï¼ˆå¢™é’Ÿæ—¶é—´ã€æ¨¡å‹è°ƒç”¨æ¬¡æ•°ï¼‰
3. æ£€æŸ¥å†…å­˜å ç”¨ï¼ˆæ‰¹é‡è®¡ç®—å¯èƒ½æ¶ˆè€—æ›´å¤šå†…å­˜ï¼‰
"""

import torch
import numpy as np
import time
from typing import Dict, Any
import sys
import os

# æ·»åŠ è·¯å¾„
REPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.insert(0, REPO_ROOT)
sys.path.insert(0, os.path.join(REPO_ROOT, "temp_aepsych"))

# å¯¼å…¥é‡‡é›†å‡½æ•°
from extensions.dynamic_eur_acquisition.eur_anova_pair_acquisition import (
    EURAnovaPairAcqf,
)
from extensions.dynamic_eur_acquisition.eur_anova_pair_acquisition_optimized import (
    EURAnovaPairAcqf_BatchOptimized,
)

# å¯¼å…¥æ¨¡å‹ç›¸å…³
from aepsych.models import OrdinalGPModel
from aepsych.likelihoods import OrdinalLikelihood
from gpytorch.kernels import RBFKernel, ScaleKernel


def create_test_model(n_train=30, dim=6, n_levels=5):
    """åˆ›å»ºæµ‹è¯•æ¨¡å‹"""
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    torch.manual_seed(42)
    np.random.seed(42)

    X_train = torch.rand(n_train, dim)
    y_train = torch.randint(0, n_levels, (n_train,)).float()

    # åˆ›å»ºæ¨¡å‹
    likelihood = OrdinalLikelihood(n_levels=n_levels)
    model = OrdinalGPModel(
        dim=dim,
        likelihood=likelihood,
        covar_module=ScaleKernel(RBFKernel(ard_num_dims=dim)),
    )

    # æ‹Ÿåˆæ•°æ®
    model.fit(X_train, y_train)

    return model, X_train, y_train


def count_metric_calls(acqf, X_test):
    """ç»Ÿè®¡ _metric è°ƒç”¨æ¬¡æ•°"""
    call_count = 0
    original_metric = acqf._metric

    def wrapped_metric(X):
        nonlocal call_count
        call_count += 1
        return original_metric(X)

    acqf._metric = wrapped_metric
    _ = acqf(X_test)
    acqf._metric = original_metric

    return call_count


def test_numerical_consistency():
    """æµ‹è¯•1ï¼šéªŒè¯æ•°å€¼ä¸€è‡´æ€§"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•1: æ•°å€¼ä¸€è‡´æ€§éªŒè¯")
    print("=" * 80)

    # åˆ›å»ºæ¨¡å‹
    model, X_train, y_train = create_test_model()

    # é…ç½®å‚æ•°ï¼ˆä¸linearå®éªŒç›¸åŒï¼‰
    config = {
        "gamma": 0.25,
        "main_weight": 1.0,
        "use_dynamic_lambda": True,
        "tau1": 0.7,
        "tau2": 0.3,
        "lambda_min": 0.1,
        "lambda_max": 1.0,
        "interaction_pairs": "0,1;2,3;4,5",
        "local_jitter_frac": 0.08,
        "local_num": 4,
        "variable_types_list": "categorical, integer, integer, continuous, categorical, integer",
    }

    # åˆ›å»ºä¸¤ä¸ªé‡‡é›†å‡½æ•°
    acqf_original = EURAnovaPairAcqf(model, **config)
    acqf_optimized = EURAnovaPairAcqf_BatchOptimized(model, **config)

    # å‡†å¤‡æµ‹è¯•å€™é€‰ç‚¹
    torch.manual_seed(123)
    X_test = torch.rand(10, 6)  # 10ä¸ªå€™é€‰ç‚¹

    # è®¡ç®—ç»“æœ (é€ä¸ªè¯„ä¼°ï¼Œå› ä¸ºé‡‡é›†å‡½æ•°è¦æ±‚ q=1)
    result_original = []
    result_optimized = []
    with torch.no_grad():
        for i in range(X_test.shape[0]):
            # ä¸ºæ¯ä¸ªå€™é€‰ç‚¹è®¾ç½®ç›¸åŒçš„éšæœºç§å­
            torch.manual_seed(1000 + i)
            np.random.seed(1000 + i)
            result_original.append(acqf_original(X_test[i : i + 1]))

            torch.manual_seed(1000 + i)
            np.random.seed(1000 + i)
            result_optimized.append(acqf_optimized(X_test[i : i + 1]))

    result_original = torch.cat(result_original)
    result_optimized = torch.cat(result_optimized)

    # æ•°å€¼æ¯”è¾ƒ
    abs_diff = torch.abs(result_original - result_optimized)
    rel_diff = abs_diff / (torch.abs(result_original) + 1e-8)

    print(f"\nç»“æœå½¢çŠ¶: {result_original.shape}")
    print(f"åŸå§‹ç‰ˆæœ¬: {result_original[:5].numpy()}")
    print(f"ä¼˜åŒ–ç‰ˆæœ¬: {result_optimized[:5].numpy()}")
    print(
        f"\nç»å¯¹å·®å¼‚: max={abs_diff.max().item():.2e}, mean={abs_diff.mean().item():.2e}"
    )
    print(
        f"ç›¸å¯¹å·®å¼‚: max={rel_diff.max().item():.2e}, mean={rel_diff.mean().item():.2e}"
    )

    # åˆ¤æ–­æ˜¯å¦ä¸€è‡´
    is_close = torch.allclose(result_original, result_optimized, atol=1e-6, rtol=1e-5)

    if is_close:
        print("\nâœ… æ•°å€¼ä¸€è‡´æ€§éªŒè¯é€šè¿‡ï¼")
        return True
    else:
        print("\nâŒ æ•°å€¼ä¸€è‡´æ€§éªŒè¯å¤±è´¥ï¼")
        print(f"   å·®å¼‚æœ€å¤§çš„ç´¢å¼•: {abs_diff.argmax().item()}")
        print(f"   åŸå§‹å€¼: {result_original[abs_diff.argmax()]}")
        print(f"   ä¼˜åŒ–å€¼: {result_optimized[abs_diff.argmax()]}")
        return False


def test_performance():
    """æµ‹è¯•2ï¼šæ€§èƒ½å¯¹æ¯”"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•2: æ€§èƒ½å¯¹æ¯”")
    print("=" * 80)

    # åˆ›å»ºæ¨¡å‹
    model, X_train, y_train = create_test_model(n_train=50)  # æ›´å¤šè®­ç»ƒæ•°æ®

    # é…ç½®å‚æ•°
    config = {
        "gamma": 0.25,
        "main_weight": 1.0,
        "use_dynamic_lambda": True,
        "tau1": 0.7,
        "tau2": 0.3,
        "lambda_min": 0.1,
        "lambda_max": 1.0,
        "interaction_pairs": "0,1;2,3;4,5",
        "local_jitter_frac": 0.08,
        "local_num": 4,
        "variable_types_list": "categorical, integer, integer, continuous, categorical, integer",
    }

    # åˆ›å»ºä¸¤ä¸ªé‡‡é›†å‡½æ•°
    acqf_original = EURAnovaPairAcqf(model, **config)
    acqf_optimized = EURAnovaPairAcqf_BatchOptimized(model, **config)

    # å‡†å¤‡æµ‹è¯•å€™é€‰ç‚¹ï¼ˆæ¨¡æ‹Ÿå®é™…ä¼˜åŒ–åœºæ™¯ï¼‰
    torch.manual_seed(456)
    n_candidates = 50  # æ¨¡æ‹ŸBoTorchä¼˜åŒ–çš„å€™é€‰ç‚¹æ•°é‡ï¼ˆå‡å°‘ä»¥åŠ å¿«æµ‹è¯•ï¼‰
    X_test = torch.rand(n_candidates, 6)

    # æµ‹è¯•åŸå§‹ç‰ˆæœ¬
    print(f"\næµ‹è¯•é…ç½®:")
    print(f"  - å€™é€‰ç‚¹æ•°: {n_candidates}")
    print(f"  - ç»´åº¦: 6")
    print(f"  - äº¤äº’å¯¹æ•°: {len(acqf_original._pairs)}")
    print(f"  - local_num: {config['local_num']}")
    print(
        f"  - é¢„æœŸæ¨¡å‹è°ƒç”¨ (åŸå§‹): {6 + len(acqf_original._pairs)} Ã— {config['local_num']} = {(6 + len(acqf_original._pairs)) * config['local_num']} æ¬¡/å€™é€‰ç‚¹"
    )

    print("\nã€åŸå§‹ç‰ˆæœ¬ã€‘")
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    t0 = time.time()
    with torch.no_grad():
        for i in range(n_candidates):
            _ = acqf_original(X_test[i : i + 1])
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    time_original = time.time() - t0

    calls_original = count_metric_calls(
        acqf_original, X_test[0:1]
    )  # å•ä¸ªå€™é€‰ç‚¹çš„è°ƒç”¨æ¬¡æ•°

    print(f"  è€—æ—¶: {time_original:.3f}ç§’ ({n_candidates}ä¸ªå€™é€‰ç‚¹)")
    print(f"  _metric è°ƒç”¨æ¬¡æ•° (å•ä¸ªå€™é€‰ç‚¹): {calls_original}")

    # æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬
    print("\nã€ä¼˜åŒ–ç‰ˆæœ¬ã€‘")
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    t0 = time.time()
    with torch.no_grad():
        for i in range(n_candidates):
            _ = acqf_optimized(X_test[i : i + 1])
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    time_optimized = time.time() - t0

    calls_optimized = count_metric_calls(acqf_optimized, X_test[0:1])

    print(f"  è€—æ—¶: {time_optimized:.3f}ç§’ ({n_candidates}ä¸ªå€™é€‰ç‚¹)")
    print(f"  _metric è°ƒç”¨æ¬¡æ•° (å•ä¸ªå€™é€‰ç‚¹): {calls_optimized}")

    # æ€§èƒ½æå‡
    speedup = time_original / time_optimized
    call_reduction = (
        calls_original / calls_optimized if calls_optimized > 0 else float("inf")
    )

    print(f"\nã€æ€§èƒ½æå‡ã€‘")
    print(f"  âš¡ åŠ é€Ÿæ¯”: {speedup:.2f}x")
    print(f"  ğŸ“‰ æ¨¡å‹è°ƒç”¨å‡å°‘: {call_reduction:.2f}x")
    print(
        f"  ğŸ’¾ æ—¶é—´èŠ‚çœ: {time_original - time_optimized:.3f}ç§’ ({(1-time_optimized/time_original)*100:.1f}%)"
    )

    if speedup > 5:
        print("\nâœ… æ€§èƒ½æå‡æ˜¾è‘—ï¼ˆ>5xï¼‰")
    elif speedup > 2:
        print("\nâœ… æ€§èƒ½æå‡æ˜æ˜¾ï¼ˆ>2xï¼‰")
    else:
        print("\nâš ï¸ æ€§èƒ½æå‡æœ‰é™ï¼ˆ<2xï¼‰")


def test_memory_usage():
    """æµ‹è¯•3ï¼šå†…å­˜å ç”¨å¯¹æ¯”"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•3: å†…å­˜å ç”¨å¯¹æ¯”")
    print("=" * 80)

    if not torch.cuda.is_available():
        print("â„¹ï¸ GPUä¸å¯ç”¨ï¼Œè·³è¿‡GPUå†…å­˜æµ‹è¯•")
        return

    # åˆ›å»ºGPUæ¨¡å‹
    model, _, _ = create_test_model(n_train=50)
    model = model.cuda()

    config = {
        "gamma": 0.25,
        "main_weight": 1.0,
        "interaction_pairs": "0,1;2,3;4,5",
        "local_num": 4,
        "variable_types_list": "categorical, integer, integer, continuous, categorical, integer",
    }

    acqf_original = EURAnovaPairAcqf(model, **config)
    acqf_optimized = EURAnovaPairAcqf_BatchOptimized(model, **config)

    X_test = torch.rand(20, 6).cuda()

    # æµ‹è¯•åŸå§‹ç‰ˆæœ¬
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
    with torch.no_grad():
        for i in range(X_test.shape[0]):
            _ = acqf_original(X_test[i : i + 1])
    mem_original = torch.cuda.max_memory_allocated() / 1024**2  # MB

    # æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
    with torch.no_grad():
        for i in range(X_test.shape[0]):
            _ = acqf_optimized(X_test[i : i + 1])
    mem_optimized = torch.cuda.max_memory_allocated() / 1024**2  # MB

    print(f"\nGPU å³°å€¼å†…å­˜å ç”¨:")
    print(f"  åŸå§‹ç‰ˆæœ¬: {mem_original:.2f} MB")
    print(f"  ä¼˜åŒ–ç‰ˆæœ¬: {mem_optimized:.2f} MB")
    print(
        f"  å¢åŠ : {mem_optimized - mem_original:.2f} MB ({(mem_optimized/mem_original - 1)*100:.1f}%)"
    )

    if mem_optimized < mem_original * 2:
        print("\nâœ… å†…å­˜å¢é•¿å¯æ¥å—ï¼ˆ<2xï¼‰")
    else:
        print("\nâš ï¸ å†…å­˜å¢é•¿è¾ƒå¤§ï¼ˆ>2xï¼‰")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 80)
    print("EURAnovaPairAcqf æ‰¹é‡æ€§èƒ½ä¼˜åŒ– - å¯¹æ¯”æµ‹è¯•")
    print("=" * 80)

    # æµ‹è¯•1: æ•°å€¼ä¸€è‡´æ€§
    consistency_passed = test_numerical_consistency()

    if not consistency_passed:
        print("\nâŒ æ•°å€¼ä¸€è‡´æ€§éªŒè¯å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
        return

    # æµ‹è¯•2: æ€§èƒ½å¯¹æ¯”
    test_performance()

    # æµ‹è¯•3: å†…å­˜å ç”¨
    test_memory_usage()

    print("\n" + "=" * 80)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
    print("=" * 80)


if __name__ == "__main__":
    main()
