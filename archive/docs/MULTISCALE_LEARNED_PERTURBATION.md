# å¤šå°ºåº¦ä¸å­¦ä¹ å‹æ‰°åŠ¨çš„è¯¦ç»†è§£æ

## é—®é¢˜èƒŒæ™¯

### ç°çŠ¶ï¼šå•ä¸€å›ºå®šæ‰°åŠ¨ç­–ç•¥

å½“å‰ `_make_local_hybrid()` é‡‡ç”¨**å›ºå®šçš„å•ä¸€æ‰°åŠ¨å¹…åº¦**ï¼š

```python
# ç°åœ¨çš„åšæ³•
local_jitter_frac = 0.1  # å›ºå®šå€¼
sigma = local_jitter_frac * span[k]  # span = max - min
noise = torch.randn(B, self.local_num) * sigma  # å›ºå®šåˆ†å¸ƒ
```

**é—®é¢˜**ï¼š

- æ‰€æœ‰å€™é€‰ç‚¹ç”¨åŒä¸€æ‰°åŠ¨å®½åº¦ â†’ åœ¨å±€éƒ¨æœ€å°å€¼å’Œå…¨å±€å¹³å¦åŒºåŸŸè¡¨ç°ä¸åŒ
- åœ¨å‚æ•°ç©ºé—´çš„ä¸åŒä½ç½®ï¼Œç›¸åŒçš„å™ªå£°å¹…åº¦å¯èƒ½æ„ä¹‰å®Œå…¨ä¸åŒ
- æ— æ³•é€‚åº”æ¨¡å‹å­¦ä¹ è¿‡ç¨‹ä¸­çš„"çƒ­ç‚¹"å˜åŒ–

---

## æ–¹å‘1ï¸âƒ£ï¼šå¤šå°ºåº¦æ‰°åŠ¨ï¼ˆMulti-Scale Perturbationsï¼‰

### æ¦‚å¿µå›¾è§£

```
å½“å‰å•ä¸€å°ºåº¦ï¼š
ç‚¹ x å‘¨å›´åªæœ‰ä¸€åœˆå¾®å°æ‰°åŠ¨
    â”Œâ”€ local_num=4 ä¸ªç‚¹ï¼ˆåŠå¾„0.1*spanï¼‰
    â”‚
    x â— â† å€™é€‰ç‚¹
    â”‚
    â””â”€

æ”¹è¿›ä¸ºå¤šå°ºåº¦ï¼š
ç‚¹ x å‘¨å›´æœ‰å¤šå±‚"æ´‹è‘±"ç»“æ„
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ scale_3 = 0.3*span ï¼ˆä¸­ç­‰è·ç¦»ï¼‰
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€ scale_2 = 0.2*span ï¼ˆä¸­è·ç¦»ï¼‰
    â”‚    â”‚  â”Œâ”€â”€â”€â”€ scale_1 = 0.1*span ï¼ˆå¾®è·ç¦»ï¼‰
    â”‚    â”‚  â”‚
    x â—  x  x  x â† ä¸‰ä¸ªå°ºåº¦ï¼Œæ¯ä¸ªå°ºåº¦ 4 ä¸ªç‚¹
    â”‚    â”‚  â”‚
    â”‚    â”‚  â””â”€â”€â”€â”€ 
    â”‚    â””â”€â”€â”€â”€â”€â”€
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### ä»£ç å®ç°ç¤ºä¾‹

```python
class MultiScalePerturbation:
    """å¤šå°ºåº¦æ‰°åŠ¨ç”Ÿæˆå™¨"""
    
    def __init__(
        self,
        scales: List[float] = [0.05, 0.15, 0.3],  # ä¸‰ä¸ªå°ºåº¦
        points_per_scale: int = 3,  # æ¯ä¸ªå°ºåº¦é‡‡ 3 ä¸ªç‚¹
    ):
        """
        Args:
            scales: ç›¸å¯¹äºç‰¹å¾èŒƒå›´çš„æ‰°åŠ¨å¹…åº¦åˆ—è¡¨
            points_per_scale: æ¯ä¸ªå°ºåº¦çš„é‡‡æ ·ç‚¹æ•°
        """
        self.scales = scales
        self.points_per_scale = points_per_scale
    
    def generate(
        self,
        X_base: torch.Tensor,  # (B, d)
        feature_ranges: np.ndarray,  # (2, d)
        variable_types: Dict[int, str],
        dimension: int,  # æ‰°åŠ¨çš„ç»´åº¦
    ) -> torch.Tensor:
        """ä¸ºæŸä¸€ç»´ç”Ÿæˆå¤šå°ºåº¦æ‰°åŠ¨ç‚¹
        
        Returns:
            (B, total_points, d) where total_points = len(scales) * points_per_scale
        """
        B, d = X_base.shape
        mn = feature_ranges[0, dimension]
        mx = feature_ranges[1, dimension]
        span = mx - mn
        
        all_perturbations = []
        
        # å¯¹æ¯ä¸ªå°ºåº¦å¾ªç¯
        for scale_idx, scale in enumerate(self.scales):
            sigma = scale * span  # æ‰°åŠ¨æ ‡å‡†å·®
            vtype = variable_types.get(dimension, "continuous")
            
            # åœ¨è¿™ä¸ªå°ºåº¦é‡‡å¤šä¸ªç‚¹
            if vtype == "categorical":
                # åˆ†ç±»å˜é‡ï¼šåŒä¸€å°ºåº¦å†…é‡‡æ ·ï¼Œå®é™…ä¸Šæ˜¯å¤šæ¬¡é‡‡æ ·
                # ï¼ˆå› ä¸ºåˆ†ç±»å˜é‡åªæœ‰æœ‰é™ä¸ªå€¼ï¼‰
                perturbs = np.random.choice(
                    unique_vals,  # ä»å†å²å€¼é‡‡æ ·
                    size=(B, self.points_per_scale)
                )
                scale_perturbations = torch.from_numpy(perturbs).to(X_base.dtype)
                
            elif vtype == "integer":
                # æ•´æ•°å˜é‡ï¼šé«˜æ–¯æ‰°åŠ¨ + èˆå…¥
                noise = torch.randn(B, self.points_per_scale) * sigma
                scale_perturbations = torch.round(
                    X_base[:, dimension:dimension+1] + noise
                ).clamp(mn, mx)
                
            else:  # continuous
                # è¿ç»­å˜é‡ï¼šç›´æ¥é«˜æ–¯æ‰°åŠ¨
                noise = torch.randn(B, self.points_per_scale) * sigma
                scale_perturbations = (
                    X_base[:, dimension:dimension+1] + noise
                ).clamp(mn, mx)
            
            all_perturbations.append(scale_perturbations)
        
        # æ‹¼æ¥æ‰€æœ‰å°ºåº¦ â†’ (B, total_points)
        return torch.cat(all_perturbations, dim=1)  # (B, len(scales)*points_per_scale)
```

### ä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ

#### ä¾‹å­1ï¼šå±€éƒ¨å³°å€¼æ¢æµ‹

```
æƒ…æ™¯ï¼šç›®æ ‡å‡½æ•°æœ‰å°–å³°
        â•±â•²  â† å°–å³°ï¼ˆçª„ï¼‰
       â•±  â•²
â”€â”€â”€â”€â”€â”€â•±    â•²â”€â”€â”€â”€â”€â”€â”€

å•ä¸€å°å°ºåº¦ (0.1*span)ï¼š
  â— â— â— â—      åªèƒ½æ¢æµ‹åˆ°é™„è¿‘å¹³å¦åŒºï¼Œæ— æ³•æ•æ‰å°–å³°
     x

å¤šå°ºåº¦ (0.05, 0.15, 0.3*span)ï¼š
 â—  â—  â—       å¾®å°ºåº¦æ•æ‰å³°å€¼ç²¾ç»†ç»“æ„
   â—  â—        ä¸­å°ºåº¦å‘ç°å‘¨è¾¹ç‰¹æ€§
      x        ç²—å°ºåº¦æ¢æµ‹å…¨å±€è¶‹åŠ¿
```

#### ä¾‹å­2ï¼šå‚æ•°ç©ºé—´ä¸åŒåŒºåŸŸ

```
åœºæ™¯ï¼šé«˜ç»´ç©ºé—´ï¼ŒæŸç»´çš„é‡è¦æ€§ä¸åŒ

ç»´ j çš„å­¦ä¹ è¿›åº¦ï¼š
  åˆæœŸï¼ˆr_t=1.0ï¼‰ï¼šå‚æ•°æ–¹å·®å¤§ï¼Œéœ€è¦"å¹¿æ’’ç½‘"
    â†’ ç”¨å¤§å°ºåº¦ (0.3*span) æ¢ç´¢å…¨å±€ï¼Œæ‰¾åˆ°ä¸»æ•ˆåº”
    
  ä¸­æœŸï¼ˆr_t=0.5ï¼‰ï¼šå‚æ•°æ–¹å·®ä¸­ç­‰ï¼Œå¼€å§‹ç²¾ç»†åŒ–
    â†’ ç”¨ä¸­å°ºåº¦ (0.15*span) æ¢ç´¢é‚»åŸŸï¼Œå‘ç°äº¤äº’
    
  æ™šæœŸï¼ˆr_t=0.1ï¼‰ï¼šå‚æ•°æ–¹å·®å°ï¼Œéœ€è¦ç²¾ç¡®å®šä½
    â†’ ç”¨å°å°ºåº¦ (0.05*span) å±€éƒ¨ç²¾è°ƒï¼Œä¼˜åŒ–åˆ†ç±»è¾¹ç•Œ
```

### ä¸ç°æœ‰ä»£ç çš„èåˆç‚¹

```python
# åœ¨ EURAnovaPairAcqf.__init__ ä¸­æ·»åŠ ï¼š

self.use_multiscale = True
self.scales = [0.05, 0.15, 0.3]  # ä¸‰å±‚
self.points_per_scale = 2  # æ¯å±‚ 2 ä¸ªç‚¹ï¼ˆæ€»å…± 6 ä¸ª local pointsï¼‰

# åœ¨ _make_local_hybrid() ä¸­ï¼š
# åŸæ¥ï¼šlocal_num=4 ä¸ªç‚¹ï¼Œå•ä¸€å°ºåº¦
# æ”¹ä¸ºï¼š3 ä¸ªå°ºåº¦ Ã— 2 ä¸ªç‚¹ = 6 ä¸ªç‚¹ï¼Œå¤šå±‚æ¢ç´¢
```

---

## æ–¹å‘2ï¸âƒ£ï¼šå­¦ä¹ å‹æ‰°åŠ¨åˆ†å¸ƒï¼ˆLearned Perturbation Distributionï¼‰

### æ ¸å¿ƒæ€æƒ³

ä¸å†ä½¿ç”¨**å›ºå®šçš„é«˜æ–¯/å‡åŒ€åˆ†å¸ƒ**ï¼Œè€Œæ˜¯æ ¹æ®**æ¨¡å‹å­¦ä¹ å†ç¨‹**åŠ¨æ€è°ƒæ•´æ‰°åŠ¨å½¢çŠ¶ã€‚

### å½“å‰æ–¹å¼ vs æ”¹è¿›æ–¹å¼

```python
# ===== ç°çŠ¶ï¼šå›ºå®šåˆ†å¸ƒ =====
sigma = 0.1 * span
noise ~ N(0, ÏƒÂ²)  # æ€»æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒ

# ===== æ”¹è¿›ï¼šå­¦ä¹ åˆ†å¸ƒ =====
# æ ¹æ®ä»¥ä¸‹ä¿¡å·è°ƒæ•´å™ªå£°åˆ†å¸ƒï¼š
# 1. æ¨¡å‹åœ¨è¯¥ç»´çš„ä¸ç¡®å®šæ€§å‡å°‘é€Ÿç‡ï¼ˆå¿« â†’ ç”¨å¤§æ–¹å·®ï¼Œæ…¢ â†’ ç”¨å°æ–¹å·®ï¼‰
# 2. è¯¥ç»´å‡ºç°çš„äº¤äº’é¢‘ç‡ï¼ˆé«˜ â†’ å¢åŠ å°¾éƒ¨æƒé‡ï¼‰
# 3. è¯¥ç»´çš„é¢„æµ‹è¯¯å·®åˆ†å¸ƒï¼ˆæœ‰å¼‚å¸¸å€¼ â†’ ç”¨åšå°¾åˆ†å¸ƒï¼‰
```

### ä»£ç å®ç°æ¡†æ¶

```python
class LearnedPerturbationAdaptor:
    """æ ¹æ®å­¦ä¹ è¿‡ç¨‹è°ƒæ•´æ‰°åŠ¨åˆ†å¸ƒçš„é€‚é…å™¨"""
    
    def __init__(self):
        self.dim_learning_rates = {}  # æ¯ç»´çš„å‚æ•°æ”¶æ•›é€Ÿç‡
        self.dim_interaction_freq = {}  # æ¯ç»´å‚ä¸çš„äº¤äº’é¢‘ç‡
        self.dim_residual_stats = {}  # æ¯ç»´çš„é¢„æµ‹è¯¯å·®ç»Ÿè®¡
    
    def update_from_training(self, model, X_train, y_train):
        """ä»è®­ç»ƒæ•°æ®æ›´æ–°ç»´åº¦ç»Ÿè®¡ä¿¡æ¯"""
        
        # ğŸ“Š ä¿¡å·1ï¼šå‚æ•°æ”¶æ•›é€Ÿç‡ï¼ˆé€šè¿‡ Laplace è¿‘ä¼¼ï¼‰
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        initial_vars = self._extract_initial_param_vars(model)
        current_vars = self._extract_current_param_vars(model)
        
        for dim_idx in range(X_train.shape[1]):
            # è¯¥ç»´ç›¸å…³å‚æ•°çš„æ–¹å·®ç¼©å‡æ¯”ä¾‹
            var_reduction = (initial_vars[dim_idx] - current_vars[dim_idx]) / (
                initial_vars[dim_idx] + 1e-8
            )
            self.dim_learning_rates[dim_idx] = var_reduction  # 0-1 ä¹‹é—´
            
            # ç›´è§‰ï¼š
            # - var_reduction é«˜ (0.8) â†’ è¯¥ç»´å·²å­¦å¥½ï¼Œç”¨å°å™ªå£°ç²¾è°ƒ
            # - var_reduction ä½ (0.2) â†’ è¯¥ç»´æœªå­¦å¥½ï¼Œç”¨å¤§å™ªå£°æ¢ç´¢
        
        # ğŸ“Š ä¿¡å·2ï¼šè¯¥ç»´åœ¨äº¤äº’ä¸­çš„æ´»è·ƒåº¦
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # æ–¹æ³•ï¼šç»Ÿè®¡è¯¥ç»´å‡ºç°åœ¨"é«˜æ•ˆåº”"äº¤äº’å¯¹ä¸­çš„é¢‘ç‡
        # ï¼ˆéœ€è¦ä» ANOVA ç»“æœä¸­æå–ï¼‰
        for i, j in self.interaction_pairs:
            # å¦‚æœ Î”_ij å¾ˆå¤§ï¼Œè¯´æ˜è¿™å¯¹äº¤äº’å¾ˆé‡è¦
            if effect_magnitude[(i,j)] > threshold:
                self.dim_interaction_freq[i] += 1
                self.dim_interaction_freq[j] += 1
        
        # ç›´è§‰ï¼š
        # - interaction_freq é«˜ â†’ è¯¥ç»´å¸¸å‚ä¸äº¤äº’ï¼Œéœ€è¦"éé«˜æ–¯"çš„å¤šæ ·åŒ–
        # - interaction_freq ä½ â†’ è¯¥ç»´è¾ƒç‹¬ç«‹ï¼Œå¯ç”¨ç®€å•åˆ†å¸ƒ
        
        # ğŸ“Š ä¿¡å·3ï¼šè¯¥ç»´çš„é¢„æµ‹è¯¯å·®åˆ†å¸ƒ
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        posterior = model.posterior(X_train)
        mean = posterior.mean.squeeze(-1)
        var = posterior.variance.squeeze(-1)
        std = torch.sqrt(var)
        
        # è®¡ç®—æ ‡å‡†åŒ–æ®‹å·®
        residuals = (y_train - mean) / (std + 1e-8)
        
        # å¯¹æ¯ç»´è®¡ç®—åå¯¼æ•°ï¼Œä¼°è®¡"è¯¥ç»´å¯¹è¯¯å·®çš„è´¡çŒ®"
        for dim_idx in range(X_train.shape[1]):
            # ç®€å•å¯å‘å¼ï¼šçœ‹è¯¥ç»´çš„å€¼å˜åŒ–ä¸æ®‹å·®çš„ç›¸å…³æ€§
            corr = np.corrcoef(X_train[:, dim_idx], residuals)[0, 1]
            self.dim_residual_stats[dim_idx] = {
                'correlation': corr,
                'residual_kurtosis': kurtosis(residuals)  # å°¾éƒ¨åšåº¦
            }
    
    def get_perturbation_sampler(self, dimension: int):
        """ä¸ºè¯¥ç»´è¿”å›å­¦ä¹ è¿‡çš„æ‰°åŠ¨åˆ†å¸ƒé‡‡æ ·å‡½æ•°
        
        Returns:
            å¯è°ƒç”¨çš„å‡½æ•°ï¼šnoise_sampler(size=(B, N)) â†’ (B, N)
        """
        
        learning_rate = self.dim_learning_rates.get(dimension, 0.5)
        interaction_freq = self.dim_interaction_freq.get(dimension, 0)
        residual_stats = self.dim_residual_stats.get(dimension, {})
        
        # ===== æ„é€ è‡ªé€‚åº”åˆ†å¸ƒ =====
        
        if learning_rate > 0.7:  # è¯¥ç»´å­¦å¾—å¾ˆå¥½
            # ç­–ç•¥ï¼šç”¨çª„åˆ†å¸ƒï¼ˆé«˜æ–¯ï¼‰ï¼Œæ–¹å·®ä¸å­¦ä¹ è¿›åº¦åå‘
            def sampler(size):
                # æ–¹å·®å° â†’ ç²¾ç»†åŒ–
                std = (1 - learning_rate) * 0.05 + 0.01  # [0.01, 0.05]
                return torch.randn(size) * std
        
        elif learning_rate < 0.3:  # è¯¥ç»´å­¦å¾—ä¸å¥½
            # ç­–ç•¥ï¼šç”¨å®½åˆ†å¸ƒ + åšå°¾ï¼ˆæ›´å¤šå¼‚å¸¸æ¢ç´¢ï¼‰
            def sampler(size):
                # ç”¨æ··åˆåˆ†å¸ƒï¼š90% é«˜æ–¯ + 10% å­¦ç”Ÿtåˆ†å¸ƒï¼ˆåšå°¾ï¼‰
                noise_normal = torch.randn(size) * 0.2
                noise_t = torch.nn.functional.normalize(
                    torch.randn(size),
                    dim=0
                ) * 0.3
                mask = torch.rand(size) < 0.9
                return torch.where(mask, noise_normal, noise_t)
        
        else:  # ä¸­ç­‰å­¦ä¹ è¿›åº¦
            # ç­–ç•¥ï¼šå¹³è¡¡æ¢ç´¢ä¸ç²¾ç»†åŒ–
            def sampler(size):
                std = 0.15
                return torch.randn(size) * std
        
        # è¿›ä¸€æ­¥è°ƒæ•´ï¼šå¦‚æœè¯¥ç»´ç»å¸¸å‚ä¸äº¤äº’
        if interaction_freq > 3:  # é«˜æ´»è·ƒåº¦
            original_sampler = sampler
            def sampler(size):
                # å¢åŠ "è·³è·ƒ"æœºåˆ¶ï¼šå¶å°”çš„å¤§å¹…è·³è·ƒå¸®åŠ©æ¢ç´¢äº¤äº’è¾¹ç•Œ
                noise = original_sampler(size)
                # 20% çš„æƒ…å†µä¸‹ï¼Œæ”¾å¤§å™ªå£°ï¼ˆæ¨¡æ‹Ÿ"èƒ†æ•¢è·³è¿œ"ï¼‰
                mask = torch.rand(size) < 0.2
                return torch.where(mask, noise * 2.0, noise)
        
        return sampler
```

### å·¥ä½œæµç¨‹å›¾

```
è®­ç»ƒæ•°æ®ç§¯ç´¯
    â†“
[update_from_training]
    â”œâ†’ æå–å‚æ•°æ–¹å·®å†å²
    â”œâ†’ ç»Ÿè®¡äº¤äº’æ•ˆåº”
    â””â†’ è®¡ç®—æ®‹å·®åˆ†å¸ƒ
    â†“
æ¯ç»´éƒ½æœ‰ä¸‰ä¸ªç»Ÿè®¡é‡ï¼š
  learning_rate    (0-1)
  interaction_freq (0-d)
  residual_stats   (dict)
    â†“
[get_perturbation_sampler(dim)]
    â”œâ†’ é«˜å­¦ä¹ ç‡ â†’ çª„é«˜æ–¯
    â”œâ†’ ä½å­¦ä¹ ç‡ â†’ å®½é«˜æ–¯+åšå°¾
    â”œâ†’ é«˜äº¤äº’é¢‘ç‡ â†’ å¢åŠ è·³è·ƒ
    â””â†’ è¿”å›å®šåˆ¶é‡‡æ ·å‡½æ•°
    â†“
åœ¨ _make_local_hybrid() è°ƒç”¨é‡‡æ ·å‡½æ•°
    â””â†’ ç”Ÿæˆç»´åº¦ç‰¹å®šçš„å™ªå£°
```

---

## å¯¹æ¯”ï¼šæ”¹è¿›å‰ vs æ”¹è¿›å

### åœºæ™¯ï¼šLikert é‡è¡¨å®éªŒï¼ˆ5ç‚¹é‡è¡¨ï¼‰

```
å‡è®¾ç©ºé—´ï¼š
  ç»´ 0ï¼ˆå¼ºåº¦ï¼‰ï¼š0-10 (continuous)
  ç»´ 1ï¼ˆé¢‘ç‡ï¼‰ï¼š1-5 (categorical)
  ç»´ 2ï¼ˆæŒç»­ï¼‰ï¼š0-100 (continuous)

å½“å‰å•ä¸€å›ºå®šï¼š
  æ‰€æœ‰ç»´éƒ½ local_jitter_frac=0.1
  æ‰€æœ‰ç»´éƒ½æ˜¯é«˜æ–¯åˆ†å¸ƒ
  æ‰€æœ‰ç»´éƒ½æ˜¯å•ä¸€å°ºåº¦

æ”¹è¿›åå¤šå°ºåº¦+å­¦ä¹ ï¼š

ç»´ 0ï¼ˆå¼ºåº¦ï¼‰ï¼š
  âœ… å­¦ä¹ è¿›åº¦å¿«ï¼ˆr_t=0.1ï¼‰ 
  âœ… å¾ˆå°‘å‚ä¸äº¤äº’
  â†’ ç”¨å°å°ºåº¦ [0.01, 0.05] + çª„é«˜æ–¯
  â†’ ç²¾ç»†è°ƒæ•´æœ€ä¼˜æ„ŸçŸ¥å¼ºåº¦

ç»´ 1ï¼ˆé¢‘ç‡ï¼‰ï¼š
  âš ï¸ å­¦ä¹ è¿›åº¦æ…¢ï¼ˆr_t=0.8ï¼Œè¿˜åœ¨å­¦ï¼‰
  âœ… ç»å¸¸ä¸ç»´2äº¤äº’ï¼ˆfreq=5ï¼‰
  â†’ ç”¨ä¸­ç­‰å°ºåº¦ [0.05, 0.15, 0.3] + åšå°¾åˆ†å¸ƒ + è·³è·ƒæœºåˆ¶
  â†’ æ¢ç´¢"é¢‘ç‡-æŒç»­"äº¤äº’è¾¹ç•Œ

ç»´ 2ï¼ˆæŒç»­ï¼‰ï¼š
  âš ï¸ å­¦ä¹ è¿›åº¦ä¸­ç­‰ï¼ˆr_t=0.5ï¼‰
  âœ… ç»å¸¸ä¸ç»´1äº¤äº’ï¼ˆfreq=5ï¼‰
  â†’ ç”¨å¤šå°ºåº¦ [0.05, 0.15] + ä¸­ç­‰é«˜æ–¯
  â†’ å¹³è¡¡ç²¾è°ƒå’Œäº¤äº’æ¢ç´¢
```

---

## å®ç°å¤æ‚åº¦è¯„ä¼°

| æ–¹æ¡ˆ | å®ç°éš¾åº¦ | æ€§èƒ½å¼€é”€ | æ•ˆæœæå‡ | æ¨èåº¦ |
|-----|--------|--------|--------|-------|
| **å¤šå°ºåº¦** | â­â­â˜†â˜†â˜† | ä½ï¼ˆåŒæ ·O(1)è¯„ä¼°ï¼‰ | â­â­â­â­â˜† | ğŸŸ¢ é«˜ |
| **å­¦ä¹ åˆ†å¸ƒ** | â­â­â­â˜†â˜† | ä¸­ç­‰ï¼ˆé¢å¤–ç»Ÿè®¡ï¼‰ | â­â­â­â­â­ | ğŸŸ¡ ä¸­ |
| **ä¸¤è€…ç»“åˆ** | â­â­â­â­â˜† | ä¸­ç­‰ | â­â­â­â­â­ | ğŸŸ¡ çœ‹åœºæ™¯ |

---

## ä½•æ—¶åº”ç”¨è¿™äº›æ”¹è¿›ï¼Ÿ

### âœ… å¤šå°ºåº¦é€‚åˆä»¥ä¸‹åœºæ™¯

- é¢„ç®—æœ‰é™ï¼ˆ20-40 trialsï¼‰ï¼Œéœ€è¦å¤šå±‚æ¬¡ä¿¡æ¯
- ç›®æ ‡å‡½æ•°æœ‰å¤šä¸ªå°ºåº¦çš„ç‰¹æ€§ï¼ˆå±€éƒ¨å³°å€¼ + å…¨å±€è¶‹åŠ¿ï¼‰
- ä¸ç¡®å®šå“ªä¸ªå°ºåº¦çš„æ•ˆåº”æœ€é‡è¦

### âœ… å­¦ä¹ åˆ†å¸ƒé€‚åˆä»¥ä¸‹åœºæ™¯

- å¤šæ¬¡å®éªŒè¿­ä»£ï¼ˆèƒ½ç§¯ç´¯è¶³å¤Ÿç»Ÿè®¡ï¼‰ï¼Œå¯é€‚åº”
- æœ‰å·²çŸ¥çš„"éš¾å­¦"ç»´åº¦ï¼Œéœ€è¦ç‰¹æ®Šå¯¹å¾…
- äº¤äº’æ•ˆåº”é‡è¦ï¼Œéœ€è¦åŠ¨æ€è°ƒæ•´æ¢ç´¢ç­–ç•¥

### âŒ ä»€ä¹ˆæ—¶å€™ä¿æŒç®€å•ï¼Ÿ

- å•æ¬¡å®éªŒï¼ˆ< 15 trialsï¼‰ï¼Œä¸å€¼å¾—å¤æ‚åŒ–
- æ‰€æœ‰ç»´åº¦è¡¨ç°å‡è¡¡ï¼Œæ— ç‰¹æ®Šéš¾ç‚¹
- å·²æœ‰é¢†åŸŸçŸ¥è¯†ï¼Œå¯æ‰‹åŠ¨é…ç½®è¶…å‚
