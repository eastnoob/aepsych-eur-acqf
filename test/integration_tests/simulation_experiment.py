"""
æ¨¡æ‹Ÿå®éªŒ - ä½¿ç”¨ INI é…ç½®æ–‡ä»¶è¿›è¡Œå®Œæ•´çš„ä¸»åŠ¨å­¦ä¹ å®éª?

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨é…ç½®æ–‡ä»¶è¿›è¡Œå®é™…çš„ä¸»åŠ¨å­¦ä¹ å®éªŒã€?
è¿è¡Œ: pixi run python simulation_experiment.py
"""

import sys
import numpy as np
from pathlib import Path
import matplotlib

matplotlib.use("Agg")  # éäº¤äº’åç«?
import matplotlib.pyplot as plt

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾?
sys.path.insert(0, str(Path(__file__).parent))

# ç›´æ¥å¯¼å…¥æ¨¡å—
from acquisition_function import VarianceReductionWithCoverageAcqf
from gp_variance import GPVarianceCalculator


def true_function(X):
    """
    çœŸå®çš„æœªçŸ¥å‡½æ•°ï¼ˆå®éªŒä¸­éœ€è¦é€šè¿‡å®é™…æµ‹é‡è·å¾—ï¼?
    è¿™é‡Œä½¿ç”¨ä¸€ä¸ªåŒ…å«ä¸»æ•ˆåº”å’Œäº¤äº’æ•ˆåº”çš„å‡½æ•°

    f(x) = 2*x1 + 3*x2 - x3 + 1.5*x1*x2 - 0.8*x2*x3 + noise
    """
    return (
        2 * X[:, 0]
        + 3 * X[:, 1]
        - X[:, 2]
        + 1.5 * X[:, 0] * X[:, 1]  # äº¤äº’ 0-1
        - 0.8 * X[:, 1] * X[:, 2]  # äº¤äº’ 1-2
        + 0.1 * np.random.randn(X.shape[0])
    )


def create_simulation_config():
    """åˆ›å»ºæ¨¡æ‹Ÿå®éªŒçš„é…ç½®æ–‡ä»?""
    config_path = Path(__file__).parent / "simulation_config.ini"

    config_content = """# æ¨¡æ‹Ÿå®éªŒé…ç½®æ–‡ä»¶
# è¿™æ˜¯ä¸€ä¸ªä¼˜åŒ–çš„é…ç½®ï¼Œç”¨äºåŒ…å«äº¤äº’æ•ˆåº”çš„å‡½æ•°å­¦ä¹ 

[AcquisitionFunction]
# åŠ¨æ€äº¤äº’æƒé‡å‚æ•?
# ç”±äºæˆ‘ä»¬çŸ¥é“å‡½æ•°åŒ…å«é‡è¦çš„äº¤äº’æ•ˆåº”ï¼Œä½¿ç”¨è¾ƒå¤§çš„æƒé‡èŒƒå›?
lambda_min = 0.3
lambda_max = 2.5

# æ–¹å·®å‡å°‘é˜ˆå€?
# è°ƒæ•´ä»¥é€‚åº”å®éªŒè¿›åº¦
tau_1 = 0.6
tau_2 = 0.15

# ç©ºé—´è¦†ç›–æƒé‡
# åœ¨æ—©æœŸç»™äºˆè¾ƒå¤§æƒé‡ä»¥ç¡®ä¿è‰¯å¥½çš„ç©ºé—´è¦†ç›?
gamma = 0.4

# äº¤äº’é¡¹å®šä¹?
# æŒ‡å®šæˆ‘ä»¬æƒ³è¦å»ºæ¨¡çš„äº¤äº’æ•ˆåº?
# æ ¼å¼: (feature1, feature2);(feature3, feature4)
interaction_terms = (0,1);(1,2)

# GP å‚æ•°
noise_variance = 0.1
prior_variance = 1.0

# è¦†ç›–åº¦è®¡ç®—æ–¹æ³?
coverage_method = min_distance
"""

    with open(config_path, "w", encoding="utf-8") as f:
        f.write(config_content)

    print(f"âœ?åˆ›å»ºé…ç½®æ–‡ä»¶: {config_path}")
    return config_path


def run_simulation_experiment(
    n_initial=15, n_iterations=30, n_candidates=300, n_features=3, save_results=True
):
    """
    è¿è¡Œå®Œæ•´çš„æ¨¡æ‹Ÿå®éª?

    å‚æ•°
    ----
    n_initial : int
        åˆå§‹éšæœºæ ·æœ¬æ•?
    n_iterations : int
        ä¸»åŠ¨å­¦ä¹ è¿­ä»£æ¬¡æ•°
    n_candidates : int
        æ¯æ¬¡è¿­ä»£çš„å€™é€‰ç‚¹æ•°é‡
    n_features : int
        ç‰¹å¾æ•°é‡
    save_results : bool
        æ˜¯å¦ä¿å­˜ç»“æœ
    """

    print("=" * 70)
    print("  æ¨¡æ‹Ÿå®éªŒ: ä½¿ç”¨ INI é…ç½®çš„ä¸»åŠ¨å­¦ä¹?)
    print("=" * 70)

    # åˆ›å»ºé…ç½®æ–‡ä»¶
    config_path = create_simulation_config()

    # ä»é…ç½®æ–‡ä»¶åŠ è½½é‡‡é›†å‡½æ•?
    print("\næ­¥éª¤ 1: ä»é…ç½®æ–‡ä»¶åŠ è½½é‡‡é›†å‡½æ•?)
    acq_fn = VarianceReductionWithCoverageAcqf(config_ini_path=config_path)

    print(f"  âœ?é…ç½®åŠ è½½æˆåŠŸ")
    print(f"    - lambda èŒƒå›´: [{acq_fn.lambda_min}, {acq_fn.lambda_max}]")
    print(f"    - tau é˜ˆå€? [{acq_fn.tau_2}, {acq_fn.tau_1}]")
    print(f"    - gamma: {acq_fn.gamma}")
    print(f"    - äº¤äº’é¡? {acq_fn.interaction_terms}")

    # ç”Ÿæˆåˆå§‹éšæœºæ ·æœ¬
    print(f"\næ­¥éª¤ 2: ç”Ÿæˆ {n_initial} ä¸ªåˆå§‹éšæœºæ ·æœ?)
    np.random.seed(42)
    X_train = np.random.rand(n_initial, n_features)
    y_train = true_function(X_train)
    print(f"  âœ?åˆå§‹æ•°æ®é›? {X_train.shape}")

    # è®°å½•å®éªŒè¿‡ç¨‹
    history = {
        "iteration": [],
        "n_samples": [],
        "lambda_t": [],
        "r_t": [],
        "best_score": [],
        "mean_score": [],
        "std_score": [],
    }

    # ä¸»åŠ¨å­¦ä¹ å¾ªç¯
    print(f"\næ­¥éª¤ 3: ä¸»åŠ¨å­¦ä¹ å¾ªç¯ ({n_iterations} æ¬¡è¿­ä»?")
    print("-" * 70)

    for iteration in range(n_iterations):
        # æ‹Ÿåˆæ¨¡å‹
        acq_fn.fit(X_train, y_train)

        # ç”Ÿæˆå€™é€‰ç‚¹
        X_candidates = np.random.rand(n_candidates, n_features)

        # è¯„ä¼°å€™é€‰ç‚¹
        scores = acq_fn(X_candidates)

        # é€‰æ‹©æœ€ä½³ç‚¹
        next_X, next_idx = acq_fn.select_next(X_candidates, n_select=1)

        # "è¿›è¡Œå®éªŒ"è·å–çœŸå®å€?
        next_y = true_function(next_X)

        # æ›´æ–°è®­ç»ƒé›?
        X_train = np.vstack([X_train, next_X])
        y_train = np.concatenate([y_train, next_y])

        # è·å–å½“å‰çŠ¶æ€?
        lambda_t = acq_fn.get_current_lambda()
        r_t = acq_fn.get_variance_reduction_ratio()

        # è®°å½•å†å²
        history["iteration"].append(iteration)
        history["n_samples"].append(len(X_train))
        history["lambda_t"].append(lambda_t)
        history["r_t"].append(r_t)
        history["best_score"].append(scores[next_idx[0]])
        history["mean_score"].append(np.mean(scores))
        history["std_score"].append(np.std(scores))

        # æ¯?5 æ¬¡è¿­ä»£æ‰“å°è¿›åº?
        if iteration % 5 == 0 or iteration == n_iterations - 1:
            print(
                f"è¿­ä»£ {iteration:3d}: "
                f"æ ·æœ¬æ•?{len(X_train):3d}, "
                f"Î»_t={lambda_t:.3f}, "
                f"r_t={r_t:.3f}, "
                f"æœ€ä½³åˆ†æ•?{scores[next_idx[0]]:.4f}"
            )

    print("-" * 70)
    print(f"âœ?å®éªŒå®Œæˆï¼æœ€ç»ˆæ•°æ®é›†å¤§å°: {len(X_train)} æ ·æœ¬")

    # æœ€ç»ˆè¯„ä¼?
    print(f"\næ­¥éª¤ 4: æœ€ç»ˆè¯„ä¼?)
    print(f"  åˆå§‹æ ·æœ¬æ•? {n_initial}")
    print(f"  æœ€ç»ˆæ ·æœ¬æ•°: {len(X_train)}")
    print(f"  æ–°å¢æ ·æœ¬æ•? {len(X_train) - n_initial}")
    print(f"  æœ€ç»?Î»_t: {history['lambda_t'][-1]:.4f}")
    print(f"  æœ€ç»?r_t: {history['r_t'][-1]:.4f}")

    # ä¿å­˜ç»“æœ
    if save_results:
        save_experiment_results(history, X_train, y_train)

    # å¯è§†åŒ–ç»“æ?
    visualize_results(history)

    return X_train, y_train, history


def save_experiment_results(history, X_train, y_train):
    """ä¿å­˜å®éªŒç»“æœ"""
    print(f"\næ­¥éª¤ 5: ä¿å­˜ç»“æœ")

    # ä¿å­˜è®­ç»ƒæ•°æ®
    data_path = Path(__file__).parent / "simulation_results_data.npz"
    np.savez(data_path, X=X_train, y=y_train)
    print(f"  âœ?è®­ç»ƒæ•°æ®ä¿å­˜åˆ? {data_path}")

    # ä¿å­˜å†å²è®°å½•
    history_path = Path(__file__).parent / "simulation_results_history.npz"
    np.savez(history_path, **history)
    print(f"  âœ?å†å²è®°å½•ä¿å­˜åˆ? {history_path}")


def visualize_results(history):
    """å¯è§†åŒ–å®éªŒç»“æ?""
    print(f"\næ­¥éª¤ 6: ç”Ÿæˆå¯è§†åŒ?)

    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    fig.suptitle("æ¨¡æ‹Ÿå®éªŒç»“æœ", fontsize=16, fontweight="bold")

    iterations = history["iteration"]

    # å›?1: æ ·æœ¬æ•°å¢é•?
    ax1 = axes[0, 0]
    ax1.plot(iterations, history["n_samples"], "b-", linewidth=2)
    ax1.set_xlabel("Iteration")
    ax1.set_ylabel("Number of Samples")
    ax1.set_title("Sample Growth")
    ax1.grid(True, alpha=0.3)

    # å›?2: åŠ¨æ€æƒé‡?Î»_t
    ax2 = axes[0, 1]
    ax2.plot(iterations, history["lambda_t"], "g-", linewidth=2)
    ax2.set_xlabel("Iteration")
    ax2.set_ylabel("Lambda_t")
    ax2.set_title("Dynamic Interaction Weight")
    ax2.grid(True, alpha=0.3)

    # å›?3: æ–¹å·®å‡å°‘æ¯”ä¾‹ r_t
    ax3 = axes[1, 0]
    ax3.plot(iterations, history["r_t"], "r-", linewidth=2)
    ax3.set_xlabel("Iteration")
    ax3.set_ylabel("r_t (Variance Ratio)")
    ax3.set_title("Variance Reduction Progress")
    ax3.grid(True, alpha=0.3)

    # å›?4: é‡‡é›†åˆ†æ•°ç»Ÿè®¡
    ax4 = axes[1, 1]
    ax4.plot(iterations, history["best_score"], "b-", label="Best Score", linewidth=2)
    ax4.plot(iterations, history["mean_score"], "g--", label="Mean Score", linewidth=2)
    ax4.fill_between(
        iterations,
        np.array(history["mean_score"]) - np.array(history["std_score"]),
        np.array(history["mean_score"]) + np.array(history["std_score"]),
        alpha=0.3,
        color="green",
    )
    ax4.set_xlabel("Iteration")
    ax4.set_ylabel("Acquisition Score")
    ax4.set_title("Acquisition Scores")
    ax4.legend()
    ax4.grid(True, alpha=0.3)

    plt.tight_layout()

    # ä¿å­˜å›¾åƒ
    fig_path = Path(__file__).parent / "simulation_results.png"
    plt.savefig(fig_path, dpi=150, bbox_inches="tight")
    print(f"  âœ?å¯è§†åŒ–ç»“æœä¿å­˜åˆ°: {fig_path}")
    plt.close()


def analyze_learned_model(X_train, y_train):
    """åˆ†æå­¦ä¹ åˆ°çš„æ¨¡å‹"""
    print(f"\næ­¥éª¤ 7: æ¨¡å‹åˆ†æ")

    # é‡æ–°æ‹Ÿåˆ GP æ¨¡å‹
    gp = GPVarianceCalculator()
    interaction_terms = [(0, 1), (1, 2)]
    gp.fit(X_train, y_train, interaction_indices=interaction_terms)

    # åˆ†æä¸»æ•ˆåº”æ–¹å·?
    print(f"\nä¸»æ•ˆåº”å‚æ•°æ–¹å·?")
    for i in range(3):
        var = gp.get_main_effect_variance(i)
        print(f"  ç‰¹å¾ {i}: {var:.6f}")

    # åˆ†æäº¤äº’æ•ˆåº”æ–¹å·®
    print(f"\näº¤äº’æ•ˆåº”å‚æ•°æ–¹å·®:")
    for i, (j, k) in enumerate(interaction_terms):
        var = gp.get_interaction_effect_variance(i)
        print(f"  äº¤äº’ ({j},{k}): {var:.6f}")

    # æµ‹è¯•é›†è¯„ä¼?
    print(f"\næµ‹è¯•é›†è¯„ä¼?")
    X_test = np.random.rand(100, 3)
    y_test_true = true_function(X_test)
    y_test_pred, y_test_std = gp.predict(X_test, return_std=True)

    mse = np.mean((y_test_true - y_test_pred) ** 2)
    mae = np.mean(np.abs(y_test_true - y_test_pred))

    print(f"  MSE: {mse:.6f}")
    print(f"  MAE: {mae:.6f}")
    print(f"  é¢„æµ‹æ ‡å‡†å·? {np.mean(y_test_std):.6f}")


def main():
    """ä¸»å‡½æ•?""
    try:
        # è¿è¡Œæ¨¡æ‹Ÿå®éªŒ
        X_train, y_train, history = run_simulation_experiment(
            n_initial=15,
            n_iterations=30,
            n_candidates=300,
            n_features=3,
            save_results=True,
        )

        # åˆ†æå­¦ä¹ åˆ°çš„æ¨¡å‹
        analyze_learned_model(X_train, y_train)

        print("\n" + "=" * 70)
        print("  ğŸ‰ æ¨¡æ‹Ÿå®éªŒæˆåŠŸå®Œæˆï¼?)
        print("=" * 70)
        print("\nç”Ÿæˆçš„æ–‡ä»?")
        print("  - simulation_config.ini        (é…ç½®æ–‡ä»¶)")
        print("  - simulation_results_data.npz  (è®­ç»ƒæ•°æ®)")
        print("  - simulation_results_history.npz (å†å²è®°å½•)")
        print("  - simulation_results.png       (å¯è§†åŒ–ç»“æ?")
        print("\nå®éªŒè¯æ˜:")
        print("  âœ?INI é…ç½®æ–‡ä»¶å¯ä»¥æ­£ç¡®åŠ è½½å’Œä½¿ç”?)
        print("  âœ?é‡‡é›†å‡½æ•°åœ¨ä¸»åŠ¨å­¦ä¹ ä¸­æ­£å¸¸å·¥ä½œ")
        print("  âœ?åŠ¨æ€æƒé‡æœºåˆ¶æŒ‰é¢„æœŸè°ƒæ•´")
        print("  âœ?å¯ä»¥æœ‰æ•ˆå­¦ä¹ åŒ…å«äº¤äº’æ•ˆåº”çš„å‡½æ•?)

        return 0

    except Exception as e:
        print(f"\nâœ?å®éªŒå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
