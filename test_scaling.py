"""
æµ‹è¯•ä¸åŒè§„æ¨¡è®¾è®¡ä¸‹çš„æ€§èƒ½æå‡

ç›®æ ‡ï¼šéªŒè¯ç»´åº¦å’Œäº¤äº’å¯¹æ•°é‡å¢åŠ æ—¶ï¼Œæ‰¹é‡ä¼˜åŒ–çš„åŠ é€Ÿæ¯”æ˜¯å¦æå‡
"""

import torch
import numpy as np
import time
from typing import Dict, Any
import sys
import os

REPO_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
sys.path.insert(0, REPO_ROOT)
sys.path.insert(0, os.path.join(REPO_ROOT, "temp_aepsych"))

from extensions.dynamic_eur_acquisition.eur_anova_pair_acquisition import (
    EURAnovaPairAcqf,
)
from extensions.dynamic_eur_acquisition.eur_anova_pair_acquisition_optimized import (
    EURAnovaPairAcqf_BatchOptimized,
)
from aepsych.models import OrdinalGPModel
from aepsych.likelihoods import OrdinalLikelihood
from gpytorch.kernels import RBFKernel, ScaleKernel


def create_model(dim, n_train=50):
    """åˆ›å»ºæŒ‡å®šç»´åº¦çš„æ¨¡å‹"""
    torch.manual_seed(42)
    np.random.seed(42)

    X_train = torch.rand(n_train, dim)
    y_train = torch.randint(0, 5, (n_train,)).float()

    likelihood = OrdinalLikelihood(n_levels=5)
    model = OrdinalGPModel(
        dim=dim,
        likelihood=likelihood,
        covar_module=ScaleKernel(RBFKernel(ard_num_dims=dim)),
    )
    model.fit(X_train, y_train)
    return model


def count_metric_calls(acqf, X_test):
    """ç»Ÿè®¡ _metric è°ƒç”¨æ¬¡æ•°"""
    call_count = 0
    original_metric = acqf._metric

    def wrapped_metric(X):
        nonlocal call_count
        call_count += 1
        return original_metric(X)

    acqf._metric = wrapped_metric
    with torch.no_grad():
        _ = acqf(X_test)
    acqf._metric = original_metric

    return call_count


def test_scaling(dim, n_pairs, n_candidates=30):
    """æµ‹è¯•æŒ‡å®šç»´åº¦å’Œäº¤äº’å¯¹æ•°é‡çš„æ€§èƒ½"""
    print(f"\n{'='*80}")
    print(f"æµ‹è¯•é…ç½®: dim={dim}, äº¤äº’å¯¹æ•°={n_pairs}, å€™é€‰ç‚¹æ•°={n_candidates}")
    print(f"{'='*80}")

    # åˆ›å»ºæ¨¡å‹
    model = create_model(dim)

    # ç”Ÿæˆäº¤äº’å¯¹ï¼ˆç›¸é‚»é…å¯¹ï¼‰
    pairs = [(i, i + 1) for i in range(0, min(dim - 1, n_pairs * 2), 2)][:n_pairs]
    pairs_str = ";".join([f"{i},{j}" for i, j in pairs])

    # ç”Ÿæˆå˜é‡ç±»å‹ï¼ˆäº¤æ›¿ categorical, integer, continuousï¼‰
    var_types = []
    for i in range(dim):
        if i % 3 == 0:
            var_types.append("categorical")
        elif i % 3 == 1:
            var_types.append("integer")
        else:
            var_types.append("continuous")
    var_types_str = ", ".join(var_types)

    config = {
        "gamma": 0.25,
        "main_weight": 1.0,
        "use_dynamic_lambda": True,
        "tau1": 0.7,
        "tau2": 0.3,
        "lambda_min": 0.1,
        "lambda_max": 1.0,
        "interaction_pairs": pairs_str,
        "local_jitter_frac": 0.08,
        "local_num": 4,
        "variable_types_list": var_types_str,
    }

    print(f"äº¤äº’å¯¹: {pairs}")
    print(
        f"å˜é‡ç±»å‹: {var_types[:6]}..."
        if len(var_types) > 6
        else f"å˜é‡ç±»å‹: {var_types}"
    )

    # åˆ›å»ºé‡‡é›†å‡½æ•°
    try:
        acqf_original = EURAnovaPairAcqf(model, **config)
        acqf_optimized = EURAnovaPairAcqf_BatchOptimized(model, **config)
    except Exception as e:
        print(f"âŒ åˆ›å»ºé‡‡é›†å‡½æ•°å¤±è´¥: {e}")
        return None

    # å‡†å¤‡æµ‹è¯•æ•°æ®
    torch.manual_seed(456)
    X_test = torch.rand(n_candidates, dim)

    # ç†è®ºæ¨¡å‹è°ƒç”¨æ¬¡æ•°
    theoretical_calls = dim + n_pairs  # ä¸»æ•ˆåº” + äº¤äº’æ•ˆåº”
    print(f"ç†è®ºæ¨¡å‹è°ƒç”¨æ¬¡æ•° (åŸå§‹): {dim} + {n_pairs} = {theoretical_calls} æ¬¡/å€™é€‰ç‚¹")

    # æµ‹è¯•åŸå§‹ç‰ˆæœ¬
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    t0 = time.time()
    with torch.no_grad():
        for i in range(n_candidates):
            _ = acqf_original(X_test[i : i + 1])
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    time_original = time.time() - t0

    calls_original = count_metric_calls(acqf_original, X_test[0:1])

    # æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    t0 = time.time()
    with torch.no_grad():
        for i in range(n_candidates):
            _ = acqf_optimized(X_test[i : i + 1])
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    time_optimized = time.time() - t0

    calls_optimized = count_metric_calls(acqf_optimized, X_test[0:1])

    # è®¡ç®—æ€§èƒ½æå‡
    speedup = time_original / time_optimized if time_optimized > 0 else float("inf")
    call_reduction = (
        calls_original / calls_optimized if calls_optimized > 0 else float("inf")
    )

    print(f"\nã€åŸå§‹ç‰ˆæœ¬ã€‘")
    print(f"  è€—æ—¶: {time_original:.3f}ç§’")
    print(f"  _metric è°ƒç”¨: {calls_original} æ¬¡/å€™é€‰ç‚¹")

    print(f"\nã€ä¼˜åŒ–ç‰ˆæœ¬ã€‘")
    print(f"  è€—æ—¶: {time_optimized:.3f}ç§’")
    print(f"  _metric è°ƒç”¨: {calls_optimized} æ¬¡/å€™é€‰ç‚¹")

    print(f"\nã€æ€§èƒ½æå‡ã€‘")
    print(f"  âš¡ åŠ é€Ÿæ¯”: {speedup:.2f}x")
    print(f"  ğŸ“‰ æ¨¡å‹è°ƒç”¨å‡å°‘: {call_reduction:.2f}x")
    print(
        f"  ğŸ’¾ æ—¶é—´èŠ‚çœ: {time_original - time_optimized:.3f}ç§’ ({(1-time_optimized/time_original)*100:.1f}%)"
    )

    return {
        "dim": dim,
        "n_pairs": n_pairs,
        "theoretical_calls": theoretical_calls,
        "calls_original": calls_original,
        "calls_optimized": calls_optimized,
        "time_original": time_original,
        "time_optimized": time_optimized,
        "speedup": speedup,
        "call_reduction": call_reduction,
    }


def main():
    """æµ‹è¯•ä¸åŒè§„æ¨¡çš„è®¾è®¡"""
    print("=" * 80)
    print("æ‰¹é‡ä¼˜åŒ–æ€§èƒ½ - è§„æ¨¡ç¼©æ”¾æµ‹è¯•")
    print("=" * 80)

    # æµ‹è¯•é…ç½®ï¼š(ç»´åº¦, äº¤äº’å¯¹æ•°, å€™é€‰ç‚¹æ•°)
    test_configs = [
        (6, 3, 30),  # å°è§„æ¨¡ï¼ˆå½“å‰linearå®éªŒï¼‰
        (10, 5, 30),  # ä¸­ç­‰è§„æ¨¡
        (15, 7, 30),  # è¾ƒå¤§è§„æ¨¡
        (20, 10, 20),  # å¤§è§„æ¨¡ï¼ˆå‡å°‘å€™é€‰ç‚¹ä»¥åŠ å¿«æµ‹è¯•ï¼‰
    ]

    results = []
    for dim, n_pairs, n_candidates in test_configs:
        result = test_scaling(dim, n_pairs, n_candidates)
        if result:
            results.append(result)

    # æ±‡æ€»ç»“æœ
    print(f"\n{'='*80}")
    print("æ±‡æ€»ç»“æœ")
    print(f"{'='*80}")
    print(
        f"\n{'ç»´åº¦':<6} {'äº¤äº’å¯¹':<8} {'ç†è®ºè°ƒç”¨':<10} {'å®é™…è°ƒç”¨(åŸ)':<14} {'å®é™…è°ƒç”¨(ä¼˜)':<14} {'åŠ é€Ÿæ¯”':<10} {'è°ƒç”¨å‡å°‘':<10}"
    )
    print(f"{'-'*80}")

    for r in results:
        print(
            f"{r['dim']:<6} {r['n_pairs']:<8} {r['theoretical_calls']:<10} "
            f"{r['calls_original']:<14} {r['calls_optimized']:<14} "
            f"{r['speedup']:<10.2f} {r['call_reduction']:<10.2f}"
        )

    # åˆ†æè¶‹åŠ¿
    print(f"\n{'='*80}")
    print("è¶‹åŠ¿åˆ†æ")
    print(f"{'='*80}")

    if len(results) >= 2:
        speedups = [r["speedup"] for r in results]
        dims = [r["dim"] for r in results]

        print(f"\nç»´åº¦å¢åŠ æ—¶çš„åŠ é€Ÿæ¯”å˜åŒ–:")
        for i, (d, s) in enumerate(zip(dims, speedups)):
            print(f"  dim={d:2d}: {s:.2f}x")

        if speedups[-1] > speedups[0]:
            improvement = (speedups[-1] / speedups[0] - 1) * 100
            print(f"\nâœ… åŠ é€Ÿæ¯”éšç»´åº¦å¢åŠ è€Œæå‡")
            print(
                f"   ä» {speedups[0]:.2f}x æå‡åˆ° {speedups[-1]:.2f}x (æå‡ {improvement:.1f}%)"
            )
        else:
            print(f"\nâš ï¸ åŠ é€Ÿæ¯”æœªéšç»´åº¦æ˜æ˜¾æå‡")

    print(f"\n{'='*80}")


if __name__ == "__main__":
    main()
